import json
import os

from sayou.core.base_component import BaseComponent
from sayou.llm.pipeline import LLMPipeline
from sayou.extractor.pipeline import ExtractorPipeline
from sayou.rag.interfaces.base_fetcher import BaseFetcher
from typing import List, Dict, Any


class SimpleKGContextFetcher(BaseFetcher):
    """
    Assemblerê°€ ì €ì¥í•œ KG íŒŒì¼ì„ ì½ì–´ RAG Contextë¡œ ë³€í™˜í•˜ëŠ” Fetcher
    """
    component_name = "SimpleKGContextFetcher"
    
    def __init__(self, extractor: ExtractorPipeline):
        self.extractor = extractor
        self.kg_path = None
        self.base_dir = None

    def initialize(self, base_dir: str, **kwargs):
        super().initialize(**kwargs)
        self.base_dir = base_dir
        self.extractor.initialize(base_dir=base_dir, **kwargs)

    def _do_fetch(self, queries: List[str], trace_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """RAGExecutorê°€ í˜¸ì¶œí•˜ëŠ” ì‹¤ì œ ë¡œì§"""
        if not self.kg_path:
            raise ValueError("kg_path was not set by RAGStage.")
            
        filepath_relative = os.path.basename(self.kg_path)
        raw_json_str = self.extractor.retrieve({"type": "file_read", "filepath": filepath_relative, "base_dir": self.base_dir})
        
        try:
            kg_data = json.loads(raw_json_str)
            refined_contexts = []
            for entity_id, data in kg_data.get("entities", {}).items():
                name = data.get("friendly_name", "").replace("<b>", "").replace("</b>", "")
                t = data.get("attributes", {}).get("sayou:totalTime", "ì•Œ ìˆ˜ ì—†ìŒ")
                refined_contexts.append(f"- {name} (ì†Œìš” ì‹œê°„: {t}ì´ˆ)")
            return [{"chunk_content": "\n".join(refined_contexts)}]
        except Exception as e:
            return [{"chunk_content": raw_json_str}] # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜


class RAGExecutionStage(BaseComponent):
    """
    RAG íŒŒì´í”„ë¼ì¸ì˜ ìµœì¢… ë‹¨ê³„ (Extractor + LLM).
    'sayou-rag'ê°€ 'sayou-extractor'ì™€ 'sayou-llm'ì„ ë„êµ¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    component_name = "RAGExecutionStage"

    def __init__(self, 
        extractor_pipeline: ExtractorPipeline,
        llm_pipeline: LLMPipeline
    ):
        super().__init__()
        self.extractor = extractor_pipeline
        self.llm = llm_pipeline
        self.context_fetcher = SimpleKGContextFetcher(self.extractor)

    def initialize(self, **kwargs):
        """ë„êµ¬ë“¤(Extractor, LLM)ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        super().initialize(**kwargs)
        self.context_fetcher.initialize(**kwargs) 
        self.llm.initialize(**kwargs)

    def run(self, query: str, kg_path: str, **kwargs) -> dict:
        """
        [ê³„ì•½] queryì™€ kg_pathë¥¼ ë°›ì•„ RAGë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        1. Context Fetcher (Extractor ì‚¬ìš©)
        2. LLM Pipeline (LLM ì‚¬ìš©)
        """
        self._log(f"Running RAG Stage with query: {query}")

        # 1. Extractorë¡œ KGì—ì„œ Context ì¶”ì¶œ
        self.context_fetcher.kg_path = kg_path # ğŸ‘ˆ ë™ì ìœ¼ë¡œ KG ê²½ë¡œ ì£¼ì…
        # _do_fetchëŠ” RAGExecutorê°€ í˜¸ì¶œí•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì§ì ‘ í˜¸ì¶œë¡œ ë‹¨ìˆœí™”
        context_chunks = self.context_fetcher._do_fetch(queries=[query], trace_result={})
        context_str = context_chunks[0]["chunk_content"]

        # 2. LLM(ë„êµ¬)ì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
        self._log("Generating final answer...")
        llm_result = self.llm.run(query=query, context=context_str) # ğŸ‘ˆ context ì£¼ì…

        return {
            "answer": llm_result["answer"],
            "context": context_str # ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ë„ ë°˜í™˜
        }