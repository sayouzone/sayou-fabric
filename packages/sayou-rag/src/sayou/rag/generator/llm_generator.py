from sayou.rag.interfaces.base_generator import BaseGenerator
from sayou.llm.interfaces.base_llm_client import BaseLLMClient # π‘ 'λ„κµ¬' νƒ€μ…
from typing import Dict, Any, List

class SayouLLMGenerator(BaseGenerator):
    """
    (T2) sayou-llm ν΄λΌμ΄μ–ΈνΈλ¥Ό μ‚¬μ©ν•΄ μµμΆ… λ‹µλ³€μ„ μƒμ„±.
    'λ„κµ¬'λ¥Ό μƒμ„±μμ—μ„ μ§μ ‘ μ£Όμ…λ°›μµλ‹λ‹¤.
    """
    component_name = "SayouLLMGenerator"

    def __init__(self, llm_client: BaseLLMClient):
        """
        Args:
            llm_client (BaseLLMClient): 
                λ‹µλ³€ μƒμ„±μ— μ‚¬μ©ν•  sayou-llmμ T1 μΈν„°νμ΄μ¤ νΈν™ ν΄λΌμ΄μ–ΈνΈ.
        """
        self.llm_client = llm_client
        self._log("SayouLLMGenerator (Default) initialized.")

    def _do_generate(self, query: str, context: List[Dict[str, Any]], chat_history: List) -> Dict[str, Any]:
        prompt = self._build_prompt(query, context)
        
        # β­οΈ μ£Όμ…λ°›μ€ λ„κµ¬(LLM) μ‚¬μ©
        response = self.llm_client.invoke(prompt) 
        
        return {
            "answer": response.get("text", "λ‹µλ³€ μƒμ„±μ— μ‹¤ν¨ν–μµλ‹λ‹¤."),
            "metadata": response.get("metadata", {})
        }

    def _build_prompt(self, query: str, context: List[Dict[str, Any]]) -> str:
        # (ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ λ΅μ§...)
        context_str = "\n---\n".join([doc.get("chunk_content", "") for doc in context])
        return f"[Context]\n{context_str}\n\n[Query]\n{query}\n\nAnswer:"